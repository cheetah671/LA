 **Thm**
For an $n×n$ matrix $A,$ the following statements are equivalent.
1. $A$ is invertible.
2. The homogeneous system $AX=0$ has only the trivial solution.
3. The system of equations $AX=Y$ has a solution $X$ for each $Y_{n×1}\neq 0$

**Proof: Exercise**
2. The matrix $A$ is row equivalent to the identity matrix $\mathbb1_{n×n}$ 


**Corollary**
A square matrix, with either a left inverse or a right inverse, is invertible.
**Proof**
Let $A_{n×n}$
$BA=\mathbb1$
$AX = 0$ has only a trivial solution

$X=\mathbb1X=(BA)X = B(AX) = B(0)$
+

$AC = \mathbb1$ 
$ACC^{-1}= \mathbb1C^{-1} \implies A = C^{-1}$

-----


Let $AX = Y$ 
let us perform a sequence of elementary row operations.
$\downarrow$
$RX=Z$
such that $R$ is the row reduced echelon matrix form of $A$

i.e., 
$R=PA$
where $P=$ a product of elementary matrices

$PAX = PY$
$\downarrow$
$RX=PY=Z$
----

Getting the inverse of a matrix by performing elementary row operations.
We have $E_k\cdots\cdots E_2E_1A=\mathbb1$
i.e. 
$E_k\cdots\cdots E_2E_1 = A^{-1}$


also there is nothing unique about elementary *row* operations. One can use elementary *column* operations. In this case, the elementary column matrices will be multiplied on the right side of $A$.

**Vector Spaces** (or a linear space)
A *vector space* $V$ consists of the following.
1. A field $F$ of scalars.
2. A set of objects called *vectors*.
3. A rule (a binary operation) called *vector addition* which associates with each pair of vectors $\overline\alpha,\overline\beta\in V$ a vector $(\overline\alpha + \overline\beta)\in V$, called the *sum* of $\overline\alpha$ and $\overline\beta$ such that
	1. addition is commutative
		1. $\overline\alpha + \overline\beta = \overline\beta+\overline\alpha,$    $\forall \overline\alpha, \overline\beta\in V$
	2. addition is associative
		1. $(\overline\alpha + \overline\beta )+ \overline\gamma = \overline\alpha+(\overline\beta + \overline\gamma),$    $\forall \overline\alpha, \overline\beta, \overline\gamma \in V$
	3. $\exists$ a unique vector $\overline0$ called the *zero vector*, such that $\overline\alpha + \overline0 = \overline\alpha,$     $\forall \overline\alpha\in V$  
	4. for each $\overline\alpha \in V,$   $\exists$ a unique $-\overline\alpha\in V$ such that $\overline\alpha + (-\overline\alpha) = 0$  
4. A rule (a binary operation) called scalar multiplication which associates with each scalar $c\in F$ and vector $\overline\alpha \in V$ a vector $c\overline\alpha\in V$ called the product of $c$ and $\overline\alpha$ such that
	1. $1\overline\alpha = \alpha$                         also $\implies-\overline\alpha = (-1)\overline\alpha$
	2. $(c_1c_2)\overline\alpha = c_1(c_2\overline\alpha)$
	3. $c(\overline\alpha+\overline\beta) = c\overline\alpha + c\overline\beta$
	4. $(c_1 + c_2)\overline\alpha = c_1\overline\alpha + c_2\overline\alpha$

A vector space $V$ is defined over a field $F$ and has two operations, vector addition and scalar multiplication. These conditions are necessary and sufficient for the definition of a vector space.

----

For example, Consider the vector space:

$(V = F^n, F = \mathbb R, +, \cdot)$  

1. $V = F^n = \{\overline x: \overline x = (x_1, x_2, x_3, \cdots x_n), \forall x_i \in F\}$  (i.e. all $n$-tuples of the scalars of $F,$ for some fixed $n\in\mathbb N$)
2. $\overline x + \overline y = (x_1+y_1, x_2+y_2, \cdots \cdots, x_n + y_n)$ 
3. $c\overline x = (c\overline x_1, c\overline x_2, \cdots\cdots c\overline x_n)$


Let $F = \mathbb R$ and $V = F^{m×n}, A\in F^{m×n}$ and $A_{m×n}$ matrix over $F$.
$[A+B]_{ij} =  A_{ij} + B_{ij}$
$[cA]_{ij} = cA_{ij}$




