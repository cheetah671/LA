Consider:
$(V, F, \oplus, \odot), (F,+,\cdot)$
We have the following operations defined.
1. Binary Operation on Vectors: Vector Addition
	$\vec\alpha \oplus \vec\beta = \vec \gamma$     $\vec\alpha,\vec\beta,\vec\gamma \in V$ 
	$V\times V\rightarrow V$
2. Binary Operation on Scalars: Scalar 
	1. Scalar Addition
		$a +b =c$        $a,b,c \in F$
	2. Scalar Multiplication
		$a\cdot b = c$          $a,b,c \in F$
	$F\times F \rightarrow F$
3. Binary Operation on Both
	1. Scalar Multiplication
		$c\odot \vec\alpha = \vec\beta$           $c\in F, \vec\alpha, \vec\beta\in V$
		$F\times V\rightarrow V$
	2. Inner Product
		$\langle\vec\alpha, \vec\beta\rangle = c$    $c\in F, \vec\alpha, \vec\beta\in V$
		$V\times V \rightarrow F$

**Inner Product**
$\vec u . \vec v =  |\vec u||\vec v|cos\theta$
The inner product is the scalar quantity. $\implies$ output is fundamentally different from the input.
An inner Product on a vector space is an operation that assigns to each and every pair of vectors $\vec\alpha, \vec\beta \in V$ a scalar in $F$. 
It is represented as $\langle\vec \alpha, \vec\beta\rangle$

**Properties of Inner Products**
1. $\langle\vec\alpha, \vec\beta\rangle = \langle\overline{\vec\beta},\overline{\vec\alpha}\rangle$    (Conjugate Symmetry of Imaginary Numbers)
2. $\langle a\vec\alpha + b\vec\beta,\vec\gamma\rangle = a\langle\vec\alpha, \vec\gamma\rangle + b\langle\vec\beta, \vec\gamma\rangle$    (Linearity of First Argument)
3. $\langle\vec\alpha,\vec\alpha\rangle \geq 0,$ and $\langle\vec\alpha,\vec\alpha\rangle = 0 \iff \vec\alpha = \vec 0$

Example:
Consider the $\mathbb R ^2$ with the usual definitions.
If we define $\langle\vec u,\vec v \rangle = u_1v_1 + u_2  v_2$
then this will be an inner product. You can verify the properties also.
In fact, any on of the form $k_1u_1v_1 + k_2u_2v_2$ will be an inner product for $k_1, k_2 \in F$

**Definitions**
Consider two vectors $\vec u,\vec v \in V$ 

**Length**
The *length* or *norm* of a vector $\vec v$ is represented as $||\vec v||$ and is given by $$||\vec v|| = \sqrt{\langle\vec v, \vec v\rangle}$$
**Distance**
The *distance* between two vector is represented as $d(\vec u, \vec v)$ and given by
$d(\vec u, \vec v) = ||\vec u - \vec v|| = \sqrt{\langle\vec u - \vec v, \vec u - \vec v\rangle}$ 

**Orthogonal**
Two vectors $\vec u$ and $\vec v$ are said to be *orthogonal* if $\langle\vec u, \vec v\rangle = 0$


For the example of $\mathbb R^2,$ 
1. $||\vec u|| = \sqrt{\langle\vec u ,\vec u \rangle} = \sqrt {{u_1}^2 + {u_2}^2}$ 
2. $d(\vec u  ,\vec v) = \sqrt{{(u_1 - v_1}) ^ 2  +  {(u_2 - v_2)} ^ 2}$

---

Consider a set of vectors $\{\vec u_1, \vec u_2 \ldots \vec u_n\}\subseteq V$

**Orthogonal Set**
Any set of vectors, in which every distinct pair of vectors is orthogonal, is called an *orthogonal set*.

$$\langle\vec u_i, \vec u_j\rangle = 0,  \space\space \space \forall i\neq j$$
**Orthonormal Set**
Any orthogonal set, for which the inner product of every vector with itself is one, is called an *orthonormal set*.

$$\langle\vec u_i, \vec u_j\rangle = 0,  \space\space \space \forall i\neq j$$
$$\langle\vec u_i, \vec u_j\rangle = 1,  \space\space \space \forall i = j$$


**Orthogonality in $\mathbb R ^2$**

**Thm**
If $\{\vec u_1, \vec u_2, \ldots \vec u_k\}$ is an orthogonal set of non zero vectors in $\mathbb R^2,$ then the vectors are linearly independent.
**Proof**


I.e., all orthogonal sets are linearly independent, but not all linearly independent sets are orthogonal. 
Also, all basis are linearly independent, but need not be orthogonal.


Examples:
For $\mathbb R^2,$ 
$\{(1,0), (0,1)\}$ forms an orthonormal basis.
$\{(2,0), (0, -5.3)\}$  forms an orthogonal basis which is not orthonormal.
$\{(1,2), (0, 5.5)\}$ forms a basis which is neither orthonormal nor orthogonal.

**Definition**
**Orthogonal Basis**
A basis of $W$ which is orthogonal is called an *orthogonal basis*.

**Coördinates**
Let $\{\vec u_1, \vec u_2, \ldots \vec u_k\}$ be an orthogonal basis of some subspace $W$ of $\mathbb R^2.$
For every $\vec w\in W,$ the unique ordered set of scalars $c_1, c_2, \ldots, c_k$ such that
$$\vec w = c_1\vec u_1 + c_2\vec u_2 +\ldots + c_k\vec u_k$$
are called the *coördinates* of $\vec w$  with respect to the orthogonal basis $\{\vec u_1, \vec u_2, \ldots \vec u_k\}$ of $W.$

These scalars are given by 
$c_i = \frac{\vec  w.\vec u_i}{\vec u_i.\vec u_i}$ 