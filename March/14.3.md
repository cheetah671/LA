**Gauss-Jordan Elimination Method to Find the Inverse of a Matrix**
Q Find the inverse
$$A=\begin{bmatrix}2&1&-4\\-4&-1&6\\-2&2&-2\end{bmatrix}$$

Now, let us find $A^{-1}$
first, we need to augment it with the identity matrix, and then we need to perform elementary row operations on it to find the inverse.
$$A=\begin{bmatrix}2&1&-4&|&1&0&0\\-4&-1&6&|&0&1&0\\-2&2&-2&|&0&0&1\end{bmatrix}$$

$R_2\rightarrow R_2+2R_1$
$$\begin{bmatrix}2&1&-4&|&1&0&0\\0&1&-2&|&2&1&0\\-2&2&-2&|&0&0&1\end{bmatrix}$$$R_3\rightarrow R_3+R_1$
$$\begin{bmatrix}2&1&-4&|&1&0&0\\0&1&-2&|&2&1&0\\0&3&-6&|&1&0&1\end{bmatrix}$$
$R_3\rightarrow R_3-3R_2$
$$\begin{bmatrix}2&1&-4&|&1&0&0\\0&1&-2&|&2&1&0\\0&0&0&|&-5&-3&1\end{bmatrix}$$
But alas, this is not an identity matrix on the left. And thus, this matrix does not have an inverse.
Similarly, even if one had used the Adjoint-Determinant matrix method, the determinant would have been zero, and thus a matrix would not have existed.

Let us try another matrix.
$$B=\begin{bmatrix}\sqrt2&0&2\sqrt2&0\\-4\sqrt2&\sqrt2 &0&0\\0&0&1&0\\0&0&3&1\end{bmatrix}$$

$$B^{-1}=\begin{bmatrix}\frac1{\sqrt2}&0&-2&0\\2\sqrt2&\frac1{\sqrt2} &-8&0\\0&0&1&0\\0&0&-3&1\end{bmatrix}$$
This will work with either method.


**Determinant**
$$A=\begin{bmatrix}a_{11}&a_{12}\\ a_{21}&a_{22}\end{bmatrix}$$
$$det(A) = |A| = \Delta = a_{11}*a_{22}-a_{21}*a_{12}$$
$$A=\begin{bmatrix}a_{11}&a_{12}&a_{13}\\ a_{21}&a_{22}&a_{23}\\ a_{31}&a_{32}&a_{33}\end{bmatrix}$$$\Delta = a_{11}\cdot (a_{22}\cdot a_{33}-a_{32}\cdot a_{23})+ a_{12} \cdot (a_{23}\cdot a_{31}-a_{21}\cdot a_{33}) + a_{13}\cdot (a_{21}\cdot a_{32}-a_{31}\cdot a_{22})$

for the general case of an $n\times n$ matrix,

$$A=\begin{bmatrix}a_{11}&a_{12}&\ldots&a_{1n}\\ a_{21}&a_{22}&\ldots&a_{2n}\\.&.&.&.\\ a_{i1}&a_{i2}&\ldots&a_{in}\\.&.&.&.\\ a_{n1}&a_{n2}&\ldots&a_{nn}\end{bmatrix}$$

Expanding the determinant around row $i$
$$\Delta = \sum^n_{j=1}(-1)^{i+j}\cdot a_{ij}\cdot det(A_{ij})$$

Where $A_{ij}$ represents the matrix formed by deleting the $i^{th}$ row and $j^{th}$ column from $A$.
and $a_{ij}$ is the element in the $i^{th}$ row and $j^{th}$ column of $A$.


**Triangular Matrices**
If a matrix has an upper or lower triangle of zeroes (all entries on one side of a diagonal are zero) then the determinant of it is given by the product of the entries in its main (non zero) diagonal.

$A=[a_{ij}]_{n\times n}\implies det(A)=a_{11}\cdot a_{22}\ldots a_{nn} = \prod_{i=1}^na_{ii}$  




**Special Determinants**
1. If the matrix has a zero row or column, then $\Delta = 0$
2. If $B$ is obtained by interchanging two rows (or two columns) of $A,$ then $detA=-detB$ 
3. If a matrix has two identical rows, then $\Delta = 0$
4. If $B$ is obtained by multiplying a row of $A$ by $k,$ then $detB=k\cdot detA$
5. If $A,$ $B,$ and $C$ differ only in some $i^{th}$ row, and the $i^{th}$ row of $C$ is the sum of the $i^{th}$ rows of $A$ and $B,$ then $detC=detA+detB$
6. If $B$ is obtained by adding a multiple of a row (or column) of $A$ to another, then $detA=detB$

Let us apply these rules to elementary (row) matrices.
1. Interchanged rows of $\mathbb I$
	$detE = -det\mathbb I = -1$
2. Multiplying $k$ to some row of $\mathbb I$
	$det E = k\cdot det\mathbb I =k$
3. Adding a multiple of some row of $\mathbb I$ to another
	$detE= det\mathbb I = 1$


$det A\cdot B = detA\cdot detB$

**Thm**
Any square matrix is invertible if and only if its determinant is not zero.
$$A_{n \times n}\neq 0 \iff\exists A^{-1}$$
**Proof**
1. Let us start with $A_{n\times n}$ being an invertible matrix.








2. a